{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de41497f",
   "metadata": {},
   "source": [
    "# Extracting the data out of the zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "247877b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import json\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4737bff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = sqlite3.connect(\"scopus.db\")\n",
    "# cur = conn.cursor()\n",
    "\n",
    "# cur.execute(\"\"\"\n",
    "# CREATE TABLE IF NOT EXISTS papers_raw (\n",
    "#     file_id INTEGER,\n",
    "#     year INTEGER,\n",
    "#     raw_json TEXT\n",
    "# )\n",
    "# \"\"\")\n",
    "\n",
    "# conn.commit()\n",
    "# conn.close()\n",
    "\n",
    "# keep = \"ScopusData2018-2023/2018/201800000\"\n",
    "# zip_path = \"ScopusData2018-2023.zip\"\n",
    "# years = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\"]\n",
    "\n",
    "# def loader(year: int, start_id: int, end_id: int):\n",
    "#     conn = sqlite3.connect(\"scopus.db\")\n",
    "#     cur = conn.cursor()\n",
    "\n",
    "#     with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "#         for file_id in range(start_id, end_id + 1):\n",
    "#             inner_path = f\"ScopusData2018-2023/{year}/{file_id}\"\n",
    "#             try:\n",
    "#                 with z.open(inner_path) as f:\n",
    "#                     try:\n",
    "#                         obj = json.load(f)\n",
    "#                     except Exception:\n",
    "#                         continue\n",
    "#             except KeyError:\n",
    "#                 continue\n",
    "#             raw_text = json.dumps(obj, ensure_ascii=False)\n",
    "#             cur.execute(\n",
    "#                 \"\"\"\n",
    "#                 INSERT INTO papers_raw (file_id, year, raw_json)\n",
    "#                 VALUES (?, ?, ?)\n",
    "#                 \"\"\",\n",
    "#                 (file_id, year, raw_text)\n",
    "#             )\n",
    "#     conn.commit()\n",
    "#     conn.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c836ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2018\n",
    "# loader(2018, 201800000, 201802761)\n",
    "\n",
    "# # 2019\n",
    "# loader(2019, 201900000, 201903081)\n",
    "\n",
    "# # 2020\n",
    "# loader(2020, 202000000, 202003392)\n",
    "\n",
    "# # 2021\n",
    "# loader(2021, 202100000, 202103814)\n",
    "\n",
    "# # 2022\n",
    "# loader(2022, 202200000, 202204243)\n",
    "\n",
    "# # 2023\n",
    "# loader(2023, 202300000, 202302889)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f79dfc4",
   "metadata": {},
   "source": [
    "# Run the first two part of the code first to create a Database and the reason for this is because its much faster than saving in a list or dictionary. (I don't have to load 5.63 GB from extracting the zip file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c80c6e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = sqlite3.connect(\"scopus.db\")\n",
    "\n",
    "# df_2018 = pd.read_sql_query(\n",
    "#     \"\"\"\n",
    "#     SELECT file_id, year, raw_json\n",
    "#     FROM papers_raw\n",
    "#     WHERE year = 2018\n",
    "#     \"\"\",\n",
    "#     conn\n",
    "# )\n",
    "\n",
    "# conn.close()\n",
    "\n",
    "# print(df_2018.shape)\n",
    "# print(df_2018.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b41bd2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title = test_data[\"abstracts-retrieval-response\"][\"item\"][\"bibrecord\"][\"head\"][\"citation-title\"]\n",
    "# class_code = test_data[\"abstracts-retrieval-response\"][\"item\"][\"bibrecord\"][\"head\"][\"enhancement\"][\"classificationgroup\"][\"classifications\"]\n",
    "# date_of_publication = test_data[\"abstracts-retrieval-response\"][\"item\"][\"bibrecord\"][\"head\"][\"source\"][\"publicationdate\"]\n",
    "# affiliations = test_data[\"abstracts-retrieval-response\"][\"affiliation\"]\n",
    "# authors = test_data[\"abstracts-retrieval-response\"][\"authors\"]\n",
    "# author_groups = test_data[\"abstracts-retrieval-response\"][\"item\"][\"bibrecord\"][\"head\"][\"author-group\"]\n",
    "# reference = test_data[\"abstracts-retrieval-response\"][\"item\"][\"bibrecord\"][\"tail\"][\"bibliography\"][\"reference\"]\n",
    "# coredata = test_data[\"abstracts-retrieval-response\"][\"coredata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a01b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sqlite3, json, zipfile, pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "DB_PATH   = os.path.abspath(\"scopus.db\")                 # <- single source of truth\n",
    "ZIP_PATH  = os.path.abspath(\"ScopusData2018-2023.zip\")   # <- your zip\n",
    "ZIP_ROOT  = \"ScopusData2018-2023\"                        # folder name inside zip\n",
    "YEARS     = [2018, 2019, 2020, 2021, 2022, 2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9235f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables once\n",
    "with sqlite3.connect(DB_PATH) as conn:\n",
    "    conn.execute(\"PRAGMA journal_mode=WAL;\")\n",
    "    conn.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS papers_raw(\n",
    "        file_id   INTEGER PRIMARY KEY,\n",
    "        year      INTEGER,\n",
    "        raw_json  TEXT\n",
    "    )\"\"\")\n",
    "    conn.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS papers_clean(\n",
    "        file_id INTEGER PRIMARY KEY,\n",
    "        year INTEGER,\n",
    "        title TEXT,\n",
    "        abstract_text TEXT,\n",
    "        pub_year INTEGER, pub_month INTEGER, pub_day INTEGER, pub_date_iso TEXT,\n",
    "        keywords TEXT,\n",
    "        classification_codes_json TEXT,\n",
    "        affiliations_top_json TEXT,\n",
    "        affiliations_groups_json TEXT,\n",
    "        references_json TEXT\n",
    "    )\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d70a6ef1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Example: load all yearsâ€™ raw rows\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m yr \u001b[38;5;129;01min\u001b[39;00m YEARS:\n\u001b[1;32m---> 36\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[43mload_raw_year_from_zip\u001b[49m\u001b[43m(\u001b[49m\u001b[43myr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded raw \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[35], line 18\u001b[0m, in \u001b[0;36mload_raw_year_from_zip\u001b[1;34m(year)\u001b[0m\n\u001b[0;32m     15\u001b[0m file_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(file_id_str)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmember\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     19\u001b[0m         obj \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\witta\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\zipfile\\__init__.py:1620\u001b[0m, in \u001b[0;36mZipFile.open\u001b[1;34m(self, name, mode, pwd, force_zip64)\u001b[0m\n\u001b[0;32m   1616\u001b[0m zef_file \u001b[38;5;241m=\u001b[39m _SharedFile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp, zinfo\u001b[38;5;241m.\u001b[39mheader_offset,\n\u001b[0;32m   1617\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fpclose, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writing)\n\u001b[0;32m   1618\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;66;03m# Skip the file header:\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m     fheader \u001b[38;5;241m=\u001b[39m \u001b[43mzef_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msizeFileHeader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1621\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fheader) \u001b[38;5;241m!=\u001b[39m sizeFileHeader:\n\u001b[0;32m   1622\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTruncated file header\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\witta\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\zipfile\\__init__.py:809\u001b[0m, in \u001b[0;36m_SharedFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos)\n\u001b[0;32m    808\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mread(n)\n\u001b[1;32m--> 809\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtell\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def load_raw_year_from_zip(year: int):\n",
    "    rows = []\n",
    "    prefix = f\"{ZIP_ROOT}/{year}/\"     # e.g., ScopusData2018-2023/2018/\n",
    "\n",
    "    with zipfile.ZipFile(ZIP_PATH, \"r\") as z:\n",
    "        for member in z.namelist():\n",
    "            if not member.startswith(prefix): \n",
    "                continue\n",
    "            if member.endswith(\"/\"):   # skip directories\n",
    "                continue\n",
    "\n",
    "            file_id_str = os.path.basename(member)  # e.g., \"201800123\"\n",
    "            if not file_id_str.isdigit():\n",
    "                continue\n",
    "            file_id = int(file_id_str)\n",
    "\n",
    "            try:\n",
    "                with z.open(member) as f:\n",
    "                    obj = json.load(f)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            raw_text = json.dumps(obj, ensure_ascii=False)\n",
    "            rows.append((file_id, year, raw_text))\n",
    "\n",
    "    if rows:\n",
    "        with sqlite3.connect(DB_PATH) as conn:\n",
    "            conn.executemany(\n",
    "                \"INSERT OR REPLACE INTO papers_raw(file_id, year, raw_json) VALUES (?, ?, ?)\",\n",
    "                rows\n",
    "            )\n",
    "    return len(rows)\n",
    "\n",
    "# Example: load all yearsâ€™ raw rows\n",
    "for yr in YEARS:\n",
    "    n = load_raw_year_from_zip(yr)\n",
    "    print(f\"Loaded raw {yr}: {n} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9137ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def extract_fields(paper):\n",
    "    ar = paper[\"abstracts-retrieval-response\"]\n",
    "\n",
    "    item_block = ar[\"item\"]\n",
    "    bibrec = item_block[\"bibrecord\"]\n",
    "    head = bibrec[\"head\"]\n",
    "    tail = bibrec[\"tail\"] if (\"tail\" in bibrec and bibrec[\"tail\"]) else {}\n",
    "    core = ar[\"coredata\"]\n",
    "\n",
    "    # -------------------------\n",
    "    # 1) Title + Abstract\n",
    "    # -------------------------\n",
    "    title = head[\"citation-title\"]\n",
    "\n",
    "    abstract_text = None\n",
    "    if \"abstracts\" in head and head[\"abstracts\"]:\n",
    "        abs_block = head[\"abstracts\"]\n",
    "        if type(abs_block) == str:\n",
    "            txt = abs_block.strip()\n",
    "            abstract_text = txt if txt else None\n",
    "        elif \"abstract\" in abs_block and abs_block[\"abstract\"]:\n",
    "            abs_list = abs_block[\"abstract\"]\n",
    "            if type(abs_list) == dict:\n",
    "                abs_list = [abs_list]\n",
    "            parts = []\n",
    "            for entry in abs_list:\n",
    "                if type(entry) == dict and \"$\" in entry:\n",
    "                    parts.append(entry[\"$\"])\n",
    "                elif type(entry) == str:\n",
    "                    parts.append(entry)\n",
    "            if parts:\n",
    "                abstract_text = \" \".join(parts)\n",
    "\n",
    "    # -------------------------\n",
    "    # 2) Classification codes\n",
    "    # -------------------------\n",
    "    classification_codes = []\n",
    "    if (\"enhancement\" in head and\n",
    "        \"classificationgroup\" in head[\"enhancement\"] and\n",
    "        \"classifications\" in head[\"enhancement\"][\"classificationgroup\"]):\n",
    "        class_list = head[\"enhancement\"][\"classificationgroup\"][\"classifications\"]\n",
    "        if type(class_list) == dict:\n",
    "            class_list = [class_list]\n",
    "        for c in class_list:\n",
    "            code_type = c[\"@type\"] if \"@type\" in c else None\n",
    "            code_val  = c[\"classification\"] if \"classification\" in c else None\n",
    "            classification_codes.append({\"type\": code_type, \"code\": code_val})\n",
    "\n",
    "    # -------------------------\n",
    "    # 3) Publication date (+ datetime)\n",
    "    # -------------------------\n",
    "    publication_date = {\"year\": None, \"month\": None, \"day\": None, \"text\": None}\n",
    "    publication_date_dt = None\n",
    "    if (\"source\" in head and \"publicationdate\" in head[\"source\"]):\n",
    "        pub = head[\"source\"][\"publicationdate\"]\n",
    "        y = pub[\"year\"]  if \"year\"  in pub else None\n",
    "        m = pub[\"month\"] if \"month\" in pub else None\n",
    "        d = pub[\"day\"]   if \"day\"   in pub else None\n",
    "        t = pub[\"date-text\"][\"$\"] if \"date-text\" in pub and \"$\" in pub[\"date-text\"] else None\n",
    "        publication_date = {\"year\": y, \"month\": m, \"day\": d, \"text\": t}\n",
    "        if y and m and d:\n",
    "            publication_date_dt = datetime(int(y), int(m), int(d))\n",
    "\n",
    "    # -------------------------\n",
    "    # 4A) Affiliations (paper-level)\n",
    "    # -------------------------\n",
    "    affiliations_top = []\n",
    "    if \"affiliation\" in ar and ar[\"affiliation\"]:\n",
    "        aff_list = ar[\"affiliation\"]\n",
    "        if type(aff_list) == dict:\n",
    "            aff_list = [aff_list]\n",
    "        for aff in aff_list:\n",
    "            affilname = aff[\"affilname\"] if \"affilname\" in aff else None\n",
    "            city      = aff[\"affiliation-city\"] if \"affiliation-city\" in aff else None\n",
    "            country   = aff[\"affiliation-country\"] if \"affiliation-country\" in aff else None\n",
    "            affiliations_top.append({\"affilname\": affilname, \"city\": city, \"country\": country})\n",
    "\n",
    "    # -------------------------\n",
    "    # 4B) Affiliations (author-group with org + authors)\n",
    "    # -------------------------\n",
    "    affiliations_groups = []\n",
    "    if \"author-group\" in head and head[\"author-group\"]:\n",
    "        ag_list = head[\"author-group\"]\n",
    "        if type(ag_list) == dict:\n",
    "            ag_list = [ag_list]\n",
    "        for grp in ag_list:\n",
    "            aff_block = grp[\"affiliation\"] if \"affiliation\" in grp else {}\n",
    "            city    = aff_block[\"city\"]    if \"city\"    in aff_block else None\n",
    "            state   = aff_block[\"state\"]   if \"state\"   in aff_block else None\n",
    "            country = aff_block[\"country\"] if \"country\" in aff_block else None\n",
    "\n",
    "            org_names = []\n",
    "            if \"organization\" in aff_block:\n",
    "                org_field = aff_block[\"organization\"]\n",
    "                if type(org_field) in (dict, str):\n",
    "                    org_list = [org_field]\n",
    "                else:\n",
    "                    org_list = org_field\n",
    "                for org in org_list:\n",
    "                    if type(org) == dict and \"$\" in org:\n",
    "                        org_names.append(org[\"$\"])\n",
    "                    elif type(org) == str:\n",
    "                        org_names.append(org)\n",
    "\n",
    "            grp_author_names = []\n",
    "            if \"author\" in grp and grp[\"author\"]:\n",
    "                grp_authors = grp[\"author\"]\n",
    "                if type(grp_authors) == dict:\n",
    "                    grp_authors = [grp_authors]\n",
    "                for ga in grp_authors:\n",
    "                    pref = ga[\"preferred-name\"] if \"preferred-name\" in ga else {}\n",
    "                    if \"ce:given-name\" in pref:\n",
    "                        given = pref[\"ce:given-name\"]\n",
    "                    elif \"ce:given-name\" in ga:\n",
    "                        given = ga[\"ce:given-name\"]\n",
    "                    else:\n",
    "                        given = None\n",
    "                    if \"ce:surname\" in pref:\n",
    "                        surname = pref[\"ce:surname\"]\n",
    "                    elif \"ce:surname\" in ga:\n",
    "                        surname = ga[\"ce:surname\"]\n",
    "                    else:\n",
    "                        surname = None\n",
    "                    if \"ce:indexed-name\" in pref:\n",
    "                        indexed = pref[\"ce:indexed-name\"]\n",
    "                    elif \"ce:indexed-name\" in ga:\n",
    "                        indexed = ga[\"ce:indexed-name\"]\n",
    "                    else:\n",
    "                        indexed = None\n",
    "                    if given and surname:\n",
    "                        name_out = f\"{given} {surname}\"\n",
    "                    elif indexed:\n",
    "                        name_out = indexed\n",
    "                    else:\n",
    "                        name_out = \"Unknown\"\n",
    "                    grp_author_names.append(name_out)\n",
    "\n",
    "            affiliations_groups.append({\n",
    "                \"city\": city, \"state\": state, \"country\": country,\n",
    "                \"organizations\": org_names, \"authors_in_group\": grp_author_names\n",
    "            })\n",
    "\n",
    "    # -------------------------\n",
    "    # 5) References\n",
    "    # -------------------------\n",
    "    references = []\n",
    "    if tail and \"bibliography\" in tail and \"reference\" in tail[\"bibliography\"]:\n",
    "        refs_list = tail[\"bibliography\"][\"reference\"]\n",
    "        if type(refs_list) == dict:\n",
    "            refs_list = [refs_list]\n",
    "        for r in refs_list:\n",
    "            ref_info = r[\"ref-info\"] if \"ref-info\" in r else {}\n",
    "            if \"ref-title\" in ref_info and \"ref-titletext\" in ref_info[\"ref-title\"]:\n",
    "                ref_title = ref_info[\"ref-title\"][\"ref-titletext\"]\n",
    "            else:\n",
    "                ref_title = None\n",
    "            if \"ref-publicationyear\" in ref_info and \"@first\" in ref_info[\"ref-publicationyear\"]:\n",
    "                ref_year = ref_info[\"ref-publicationyear\"][\"@first\"]\n",
    "            else:\n",
    "                ref_year = None\n",
    "            full_cite = r[\"ref-fulltext\"] if \"ref-fulltext\" in r else None\n",
    "            references.append({\"title\": ref_title, \"year\": ref_year, \"full_citation\": full_cite})\n",
    "\n",
    "    # -------------------------\n",
    "    # 6) Keywords\n",
    "    # -------------------------\n",
    "    raw_keywords = core[\"authkeywords\"] if \"authkeywords\" in core else None\n",
    "    keywords = [kw.strip() for kw in raw_keywords.split(\";\")] if (type(raw_keywords) == str) else None\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"abstract_text\": abstract_text,\n",
    "        \"classification_codes\": classification_codes,\n",
    "        \"publication_date\": publication_date,\n",
    "        \"publication_date_dt\": publication_date_dt,\n",
    "        \"affiliations_top\": affiliations_top,\n",
    "        \"affiliations_groups\": affiliations_groups,\n",
    "        \"references\": references,\n",
    "        \"keywords\": keywords,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc10d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_2018' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[43mdf_2018\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_json\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      2\u001b[0m info \u001b[38;5;241m=\u001b[39m extract_fields_simple2(test_data)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTITLE:\u001b[39m\u001b[38;5;124m\"\u001b[39m, info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_2018' is not defined"
     ]
    }
   ],
   "source": [
    "# test_data = json.loads(df_2018[\"raw_json\"][0])\n",
    "# info = extract_fields_simple2(test_data)\n",
    "\n",
    "# print(\"TITLE:\", info[\"title\"])\n",
    "# print(\"ABSTRACT:\", info[\"abstract_text\"])\n",
    "# print(\"CLASS:\", info[\"classification_codes\"])\n",
    "\n",
    "# print(\"PUB DATE FIELDS:\", info[\"publication_date\"])\n",
    "# print(\"PUB DATE DATETIME:\", info[\"publication_date_dt\"])\n",
    "\n",
    "# print(\"AFFILIATIONS_TOP:\", info[\"affiliations_top\"])\n",
    "# print(\"AFFILIATIONS_GROUPS:\", info[\"affiliations_groups\"])\n",
    "# print(\"KEYWORDS:\", info[\"keywords\"])\n",
    "\n",
    "# print(\"NUM REFS:\", len(info[\"references\"]))\n",
    "# print(\"FIRST REF:\", info[\"references\"][0] if info[\"references\"] else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae30e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = sqlite3.connect(\"scopus_new.db\")\n",
    "# cur = conn.cursor()\n",
    "\n",
    "# cur.execute(\"\"\"\n",
    "# CREATE TABLE IF NOT EXISTS papers_clean (\n",
    "#     file_id INTEGER PRIMARY KEY,\n",
    "#     year INTEGER,\n",
    "#     title TEXT,\n",
    "#     abstract_text TEXT,\n",
    "#     pub_year INTEGER,\n",
    "#     pub_month INTEGER,\n",
    "#     pub_day INTEGER,\n",
    "#     pub_date_iso TEXT,\n",
    "#     keywords TEXT,\n",
    "#     classification_codes_json TEXT,\n",
    "#     affiliations_top_json TEXT,\n",
    "#     affiliations_groups_json TEXT,\n",
    "#     references_json TEXT\n",
    "# )\n",
    "# \"\"\")\n",
    "\n",
    "# conn.commit()\n",
    "# conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d919e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_row_for_db(file_id_val, year_val, info):\n",
    "    pub = info[\"publication_date\"]\n",
    "    iso = info[\"publication_date_dt\"].strftime(\"%Y-%m-%d\") if info[\"publication_date_dt\"] else None\n",
    "    kws = \"; \".join(info[\"keywords\"]) if info[\"keywords\"] else None\n",
    "\n",
    "    return (\n",
    "        int(file_id_val), int(year_val),\n",
    "        info[\"title\"], info[\"abstract_text\"],\n",
    "        pub[\"year\"], pub[\"month\"], pub[\"day\"], iso,\n",
    "        kws,\n",
    "        json.dumps(info[\"classification_codes\"], ensure_ascii=False),\n",
    "        json.dumps(info[\"affiliations_top\"],    ensure_ascii=False),\n",
    "        json.dumps(info[\"affiliations_groups\"], ensure_ascii=False),\n",
    "        json.dumps(info[\"references\"],          ensure_ascii=False)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c284d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_year_into_clean_table(target_year: int):\n",
    "    with sqlite3.connect(DB_PATH) as conn:\n",
    "        df_year = pd.read_sql_query(\n",
    "            \"SELECT file_id, year, raw_json FROM papers_raw WHERE year = ? ORDER BY file_id\",\n",
    "            conn, params=(target_year,)\n",
    "        )\n",
    "\n",
    "        rows = []\n",
    "        for _, r in df_year.iterrows():\n",
    "            paper_dict = json.loads(r[\"raw_json\"])\n",
    "            info = extract_fields(paper_dict)   # uses your strict parser\n",
    "            rows.append(make_row_for_db(r[\"file_id\"], r[\"year\"], info))\n",
    "\n",
    "        if rows:\n",
    "            conn.executemany(\"\"\"\n",
    "                INSERT OR REPLACE INTO papers_clean(\n",
    "                    file_id, year, title, abstract_text,\n",
    "                    pub_year, pub_month, pub_day, pub_date_iso,\n",
    "                    keywords, classification_codes_json,\n",
    "                    affiliations_top_json, affiliations_groups_json, references_json\n",
    "                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", rows)\n",
    "\n",
    "# Example: build clean table for all years\n",
    "for yr in YEARS:\n",
    "    load_year_into_clean_table(yr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3372f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_year_into_clean_table(target_year):\n",
    "#     # 1. pull raw rows for that year\n",
    "#     conn = sqlite3.connect(\"scopus.db\")\n",
    "#     df_year = pd.read_sql_query(\n",
    "#         \"\"\"\n",
    "#         SELECT file_id, year, raw_json\n",
    "#         FROM papers_raw\n",
    "#         WHERE year = ?\n",
    "#         ORDER BY file_id\n",
    "#         \"\"\",\n",
    "#         conn,\n",
    "#         params=(target_year,)\n",
    "#     )\n",
    "\n",
    "#     # 2. build rows for insert\n",
    "#     rows_to_insert = []\n",
    "#     for i in range(len(df_year)):\n",
    "#         file_id_val = df_year.loc[i, \"file_id\"]\n",
    "#         year_val    = df_year.loc[i, \"year\"]\n",
    "#         raw_txt     = df_year.loc[i, \"raw_json\"]\n",
    "\n",
    "#         paper_dict = json.loads(raw_txt)\n",
    "#         info = extract_fields_simple(paper_dict)  # uses the function we built\n",
    "\n",
    "#         row_tuple = make_row_for_db(file_id_val, year_val, info)\n",
    "#         rows_to_insert.append(row_tuple)\n",
    "\n",
    "#     # 3. insert into papers_clean\n",
    "#     cur = conn.cursor()\n",
    "\n",
    "#     cur.executemany(\n",
    "#         \"\"\"\n",
    "#         INSERT OR REPLACE INTO papers_clean (\n",
    "#             file_id,\n",
    "#             year,\n",
    "#             title,\n",
    "#             abstract_text,\n",
    "#             pub_year,\n",
    "    #         pub_month,\n",
    "    #         pub_day,\n",
    "    #         pub_date_iso,\n",
    "    #         keywords,\n",
    "    #         classification_codes_json,\n",
    "    #         affiliations_top_json,\n",
    "    #         affiliations_groups_json,\n",
    "    #         references_json\n",
    "    #     )\n",
    "    #     VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    #     \"\"\",\n",
    "    #     rows_to_insert\n",
    "    # )\n",
    "\n",
    "    # conn.commit()\n",
    "    # conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e69ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6cda2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract_text</th>\n",
       "      <th>pub_year</th>\n",
       "      <th>pub_month</th>\n",
       "      <th>pub_day</th>\n",
       "      <th>pub_date_iso</th>\n",
       "      <th>keywords</th>\n",
       "      <th>classification_codes_json</th>\n",
       "      <th>affiliations_top_json</th>\n",
       "      <th>affiliations_groups_json</th>\n",
       "      <th>references_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201800000</td>\n",
       "      <td>2018</td>\n",
       "      <td>Public health and international epidemiology f...</td>\n",
       "      <td>None</td>\n",
       "      <td>2018</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"type\": \"ASJC\", \"code\": \"2700\"}, {\"type\": \"S...</td>\n",
       "      <td>[{\"affilname\": \"Stanford University School of ...</td>\n",
       "      <td>[{\"city\": \"Bangkok\", \"state\": null, \"country\":...</td>\n",
       "      <td>[{\"title\": \"The untilled fields of public heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201800001</td>\n",
       "      <td>2018</td>\n",
       "      <td>Flexible Printed Active Antenna for Digital Te...</td>\n",
       "      <td>Â© 2018 The Institute of Electronics, Informati...</td>\n",
       "      <td>2018</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"type\": \"ASJC\", \"code\": [{\"$\": \"2208\"}, {\"$\"...</td>\n",
       "      <td>[{\"affilname\": \"Chulalongkorn University\", \"ci...</td>\n",
       "      <td>[{\"city\": \"Patumwan, Bangkok\", \"state\": null, ...</td>\n",
       "      <td>[{\"title\": \"Development of built-in low-profil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201800002</td>\n",
       "      <td>2018</td>\n",
       "      <td>Parametric study of hydrogen production via so...</td>\n",
       "      <td>Â© 2018 Elsevier LtdComputational fluid dynamic...</td>\n",
       "      <td>2018</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"type\": \"CPXCLASS\", \"code\": [{\"classificatio...</td>\n",
       "      <td>[{\"affilname\": \"Chulalongkorn University\", \"ci...</td>\n",
       "      <td>[{\"city\": \"Bangkok\", \"state\": null, \"country\":...</td>\n",
       "      <td>[{\"title\": \"Capture of CO2from combustion gase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201800003</td>\n",
       "      <td>2018</td>\n",
       "      <td>Superhydrophobic coating from fluoroalkylsilan...</td>\n",
       "      <td>Â© 2018 Elsevier B.V. A superhydrophobic/supero...</td>\n",
       "      <td>2018</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"type\": \"CPXCLASS\", \"code\": [{\"classificatio...</td>\n",
       "      <td>[{\"affilname\": \"Hirosaki University\", \"city\": ...</td>\n",
       "      <td>[{\"city\": \"Pathumthani\", \"state\": null, \"count...</td>\n",
       "      <td>[{\"title\": \"Ceramic membrane performance in mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201800004</td>\n",
       "      <td>2018</td>\n",
       "      <td>Electrochemical impedance-based DNA sensor usi...</td>\n",
       "      <td>Â© 2018 Elsevier B.V. A label-free electrochemi...</td>\n",
       "      <td>2018</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"type\": \"EMCLASS\", \"code\": {\"classification-...</td>\n",
       "      <td>[{\"affilname\": \"Chulalongkorn University\", \"ci...</td>\n",
       "      <td>[{\"city\": \"Bangkok\", \"state\": null, \"country\":...</td>\n",
       "      <td>[{\"title\": \"The diagnosis and misdiagnosis of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20211</th>\n",
       "      <td>202302885</td>\n",
       "      <td>2023</td>\n",
       "      <td>Long-chain bio-olefins production via oxidativ...</td>\n",
       "      <td>Â© 2021 Elsevier B.V.Long-chain Î±-olefins (â‰¥ C1...</td>\n",
       "      <td>2023</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"type\": \"CPXCLASS\", \"code\": [{\"classificatio...</td>\n",
       "      <td>[{\"affilname\": \"Chulalongkorn University\", \"ci...</td>\n",
       "      <td>[{\"city\": \"Bangkok\", \"state\": null, \"country\":...</td>\n",
       "      <td>[{\"title\": \"The chemistry and kinetics of poly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20212</th>\n",
       "      <td>202302886</td>\n",
       "      <td>2023</td>\n",
       "      <td>Recent Developments and Applications of Microf...</td>\n",
       "      <td>Â© 2021 Taylor &amp; Francis Group, LLC.Nowadays, f...</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"type\": \"CPXCLASS\", \"code\": [{\"classificatio...</td>\n",
       "      <td>[{\"affilname\": \"Chulalongkorn University\", \"ci...</td>\n",
       "      <td>[{\"city\": \"Bangkok\", \"state\": null, \"country\":...</td>\n",
       "      <td>[{\"title\": null, \"year\": \"2021\", \"full_citatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20213</th>\n",
       "      <td>202302887</td>\n",
       "      <td>2023</td>\n",
       "      <td>Social justice, education and peacebuilding: c...</td>\n",
       "      <td>Â© 2021 The Author(s). Published by Informa UK ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"type\": \"ASJC\", \"code\": \"3304\"}, {\"type\": \"S...</td>\n",
       "      <td>[{\"affilname\": \"Chulalongkorn University\", \"ci...</td>\n",
       "      <td>[{\"city\": \"London\", \"state\": null, \"country\": ...</td>\n",
       "      <td>[{\"title\": \"The Rehabilitation of Jemaah Islam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20214</th>\n",
       "      <td>202302888</td>\n",
       "      <td>2023</td>\n",
       "      <td>Effects of black soldier fly (Hermetia illucen...</td>\n",
       "      <td>Â© 2021 Taylor &amp; Francis.The effects of replaci...</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"type\": \"GEOCLASS\", \"code\": {\"classification...</td>\n",
       "      <td>[{\"affilname\": \"Chulalongkorn University\", \"ci...</td>\n",
       "      <td>[{\"city\": \"Nong Khai Province\", \"state\": null,...</td>\n",
       "      <td>[{\"title\": \"Effect of dietary carbohydrate to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20215</th>\n",
       "      <td>202302889</td>\n",
       "      <td>2023</td>\n",
       "      <td>Effects of remittances on household poverty an...</td>\n",
       "      <td>Â© 2021 Informa UK Limited, trading as Taylor &amp;...</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"type\": \"GEOCLASS\", \"code\": [{\"classificatio...</td>\n",
       "      <td>[{\"affilname\": \"Chulalongkorn University\", \"ci...</td>\n",
       "      <td>[{\"city\": \"Phnom Penh\", \"state\": null, \"countr...</td>\n",
       "      <td>[{\"title\": \"What is the Impact of Internationa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20216 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         file_id  year                                              title  \\\n",
       "0      201800000  2018  Public health and international epidemiology f...   \n",
       "1      201800001  2018  Flexible Printed Active Antenna for Digital Te...   \n",
       "2      201800002  2018  Parametric study of hydrogen production via so...   \n",
       "3      201800003  2018  Superhydrophobic coating from fluoroalkylsilan...   \n",
       "4      201800004  2018  Electrochemical impedance-based DNA sensor usi...   \n",
       "...          ...   ...                                                ...   \n",
       "20211  202302885  2023  Long-chain bio-olefins production via oxidativ...   \n",
       "20212  202302886  2023  Recent Developments and Applications of Microf...   \n",
       "20213  202302887  2023  Social justice, education and peacebuilding: c...   \n",
       "20214  202302888  2023  Effects of black soldier fly (Hermetia illucen...   \n",
       "20215  202302889  2023  Effects of remittances on household poverty an...   \n",
       "\n",
       "                                           abstract_text  pub_year  pub_month  \\\n",
       "0                                                   None      2018       12.0   \n",
       "1      Â© 2018 The Institute of Electronics, Informati...      2018       12.0   \n",
       "2      Â© 2018 Elsevier LtdComputational fluid dynamic...      2018       12.0   \n",
       "3      Â© 2018 Elsevier B.V. A superhydrophobic/supero...      2018       12.0   \n",
       "4      Â© 2018 Elsevier B.V. A label-free electrochemi...      2018       12.0   \n",
       "...                                                  ...       ...        ...   \n",
       "20211  Â© 2021 Elsevier B.V.Long-chain Î±-olefins (â‰¥ C1...      2023        1.0   \n",
       "20212  Â© 2021 Taylor & Francis Group, LLC.Nowadays, f...      2023        NaN   \n",
       "20213  Â© 2021 The Author(s). Published by Informa UK ...      2023        NaN   \n",
       "20214  Â© 2021 Taylor & Francis.The effects of replaci...      2023        NaN   \n",
       "20215  Â© 2021 Informa UK Limited, trading as Taylor &...      2023        NaN   \n",
       "\n",
       "       pub_day pub_date_iso keywords  \\\n",
       "0         31.0   2018-12-31     None   \n",
       "1         31.0   2018-12-31     None   \n",
       "2         31.0   2018-12-31     None   \n",
       "3         31.0   2018-12-31     None   \n",
       "4         31.0   2018-12-31     None   \n",
       "...        ...          ...      ...   \n",
       "20211      1.0   2023-01-01     None   \n",
       "20212      NaN         None     None   \n",
       "20213      NaN         None     None   \n",
       "20214      NaN         None     None   \n",
       "20215      NaN         None     None   \n",
       "\n",
       "                               classification_codes_json  \\\n",
       "0      [{\"type\": \"ASJC\", \"code\": \"2700\"}, {\"type\": \"S...   \n",
       "1      [{\"type\": \"ASJC\", \"code\": [{\"$\": \"2208\"}, {\"$\"...   \n",
       "2      [{\"type\": \"CPXCLASS\", \"code\": [{\"classificatio...   \n",
       "3      [{\"type\": \"CPXCLASS\", \"code\": [{\"classificatio...   \n",
       "4      [{\"type\": \"EMCLASS\", \"code\": {\"classification-...   \n",
       "...                                                  ...   \n",
       "20211  [{\"type\": \"CPXCLASS\", \"code\": [{\"classificatio...   \n",
       "20212  [{\"type\": \"CPXCLASS\", \"code\": [{\"classificatio...   \n",
       "20213  [{\"type\": \"ASJC\", \"code\": \"3304\"}, {\"type\": \"S...   \n",
       "20214  [{\"type\": \"GEOCLASS\", \"code\": {\"classification...   \n",
       "20215  [{\"type\": \"GEOCLASS\", \"code\": [{\"classificatio...   \n",
       "\n",
       "                                   affiliations_top_json  \\\n",
       "0      [{\"affilname\": \"Stanford University School of ...   \n",
       "1      [{\"affilname\": \"Chulalongkorn University\", \"ci...   \n",
       "2      [{\"affilname\": \"Chulalongkorn University\", \"ci...   \n",
       "3      [{\"affilname\": \"Hirosaki University\", \"city\": ...   \n",
       "4      [{\"affilname\": \"Chulalongkorn University\", \"ci...   \n",
       "...                                                  ...   \n",
       "20211  [{\"affilname\": \"Chulalongkorn University\", \"ci...   \n",
       "20212  [{\"affilname\": \"Chulalongkorn University\", \"ci...   \n",
       "20213  [{\"affilname\": \"Chulalongkorn University\", \"ci...   \n",
       "20214  [{\"affilname\": \"Chulalongkorn University\", \"ci...   \n",
       "20215  [{\"affilname\": \"Chulalongkorn University\", \"ci...   \n",
       "\n",
       "                                affiliations_groups_json  \\\n",
       "0      [{\"city\": \"Bangkok\", \"state\": null, \"country\":...   \n",
       "1      [{\"city\": \"Patumwan, Bangkok\", \"state\": null, ...   \n",
       "2      [{\"city\": \"Bangkok\", \"state\": null, \"country\":...   \n",
       "3      [{\"city\": \"Pathumthani\", \"state\": null, \"count...   \n",
       "4      [{\"city\": \"Bangkok\", \"state\": null, \"country\":...   \n",
       "...                                                  ...   \n",
       "20211  [{\"city\": \"Bangkok\", \"state\": null, \"country\":...   \n",
       "20212  [{\"city\": \"Bangkok\", \"state\": null, \"country\":...   \n",
       "20213  [{\"city\": \"London\", \"state\": null, \"country\": ...   \n",
       "20214  [{\"city\": \"Nong Khai Province\", \"state\": null,...   \n",
       "20215  [{\"city\": \"Phnom Penh\", \"state\": null, \"countr...   \n",
       "\n",
       "                                         references_json  \n",
       "0      [{\"title\": \"The untilled fields of public heal...  \n",
       "1      [{\"title\": \"Development of built-in low-profil...  \n",
       "2      [{\"title\": \"Capture of CO2from combustion gase...  \n",
       "3      [{\"title\": \"Ceramic membrane performance in mi...  \n",
       "4      [{\"title\": \"The diagnosis and misdiagnosis of ...  \n",
       "...                                                  ...  \n",
       "20211  [{\"title\": \"The chemistry and kinetics of poly...  \n",
       "20212  [{\"title\": null, \"year\": \"2021\", \"full_citatio...  \n",
       "20213  [{\"title\": \"The Rehabilitation of Jemaah Islam...  \n",
       "20214  [{\"title\": \"Effect of dietary carbohydrate to ...  \n",
       "20215  [{\"title\": \"What is the Impact of Internationa...  \n",
       "\n",
       "[20216 rows x 13 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "df_all = pd.read_sql_query(\n",
    "    \"SELECT * FROM papers_clean ORDER BY file_id\",\n",
    "    conn\n",
    ")\n",
    "df_all\n",
    "# import json\n",
    "\n",
    "# row = df_all.iloc[0]\n",
    "# codes = json.loads(row[\"classification_codes_json\"]) if row[\"classification_codes_json\"] else []\n",
    "# codes \n",
    "# [c[\"code\"] for c in codes if \"code\" in c] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a397377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
